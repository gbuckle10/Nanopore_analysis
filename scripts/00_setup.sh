#!/bin/bash

# Exit on error
set -e
set -o pipefail

# Source the logging utility
# Assumes that logging.sh is in the utils folder of the current folder.
source "$(dirname "$0")/utils/logging.sh"

# Read config values
CONFIG_FILE=$1
RUNTIME_CONFIG="scripts/runtime_config.sh"
DORADO_VERSION=$(yq e '.parameters.setup.dorado_version' "${CONFIG_FILE}")
FAST5_DOWNLOAD_URL=$(yq e '.paths.fast5_download_url' "${CONFIG_FILE}")
FAST5_DESTINATION_DIR=$(yq e '.paths.fast5_input_dir' "${CONFIG_FILE}")
NUM_FAST5_FILES=$(yq e '.parameters.setup.num_fast5_files' "${CONFIG_FILE}")
POD5_DIR=$(yq e '.paths.pod5_dir' "${CONFIG_FILE}")
POD5_FILE=$(yq e '.paths.pod5_name' "${CONFIG_FILE}")
SHOULD_DOWNLOAD_FAST5_FILES=$(yq e '.pipeline_control.run_setup_tasks.download_fast5_data' "${CONFIG_FILE}")
SHOULD_CONVERT_FAST5_TO_POD5=$(yq e '.pipeline_control.run_setup_tasks.convert_fast5_to_pod5' "${CONFIG_FILE}")
REFERENCE_GENOME_DIR='reference_genomes/'
REFERENCE_GENOME_URL=$(yq e '.paths.reference_genome_url' "${CONFIG_FILE}")
REFERENCE_GENOME_NAME=$(yq e '.paths.reference_genome_name' "${CONFIG_FILE}")
REFERENCE_GENOME_INDEX=$(yq e '.paths.indexed_ref_gen_name' "${CONFIG_FILE}")

check_vars \
  "DORADO_VERSION" \
  "FAST5_DOWNLOAD_URL" \
  "FAST5_DESTINATION_DIR" \
  "NUM_FAST5_FILES" \
  "POD5_DIR" \
  "POD5_FILE" \
  "SHOULD_DOWNLOAD_FAST5_FILES" \
  "SHOULD_CONVERT_FAST5_TO_POD5"

make_directories() {
  log_info "--- Creating core directory structure ---"

  # Read the list of directories from the config file into an array
  mapfile -t DIRECTORIES_TO_CREATE < <(yq '.paths.core_directories[]' "$CONFIG_FILE")

  if [ ${#DIRECTORIES_TO_CREATE[@]} -eq 0 ]; then
    log_error "Could not read core_directories from config file. Aborting."
    exit 1
  fi

  for dir in ${DIRECTORIES_TO_CREATE[@]}; do
    mkdir -p "${dir}"
  done

  log_info "Created top level directories"

  log_info "Creating new runtime config at ${RUNTIME_CONFIG}"
  cat > "${RUNTIME_CONFIG}" << EOL
#!/bin/bash
# This file is auto-generated by the setup script. Do not edit manually.
# It is sourced by other scripts to get runtime paths.

EOL
}

install_dorado() {
  log_info "--- Downloading and setting up Dorado ---"

  case "$(uname -s)" in
    Linux*)
      os_type="linux-x64"
      archive_filename="dorado.tar.gz"
      download_url="https://cdn.oxfordnanoportal.com/software/analysis/dorado-${DORADO_VERSION}-${os_type}.tar.gz"
      ;;
    CYGWIN*|MINGW*|MSYS*)
      os_type="win64"
      archive_filename="dorado.zip"
      download_url="https://cdn.oxfordnanoportal.com/software/analysis/dorado-${DORADO_VERSION}-${os_type}.zip"
      ;;
    *)
      log_error "I don't have a clue what operating system you're trying to use..."
      return 1
      ;;
  esac

  DORADO_DIR=tools/dorado-${DORADO_VERSION}-${os_type}
  log_info "--- Checking for existing Dorado installation in ${DORADO_DIR}---"
  if [ -d "${DORADO_DIR}" ]; then
    log_info "Dorado folder already exists, so I won't download it again."

  else
    log_info "Downloading dorado version ${DORADO_VERSION} for ${os_type} from ${download_url}" >&2
    curl -o tools/${archive_filename}  "$download_url"

    log_info "Download complete. Unzipping and setting up." >&2

    case ${os_type} in
      "linux-x64")
        tar -xzvf "tools/${archive_filename}" -C "tools/"
        ;;
      "win64")
        unzip -q "tools/${archive_filename}" -d "tools/"
        ;;
    esac

    folder_to_remove=tools/${archive_filename}
    log_info "Unzipping complete, removing ${folder_to_remove}"
    rm "${folder_to_remove}"
  fi

  LOCAL_DORADO_BIN="${DORADO_DIR}/bin"
  export PATH="$LOCAL_DORADO_BIN:$PATH"
  log_info "The local dorado binary is in ${LOCAL_DORADO_BIN}"

  DORADO_EXECUTABLE_PATH=$(realpath "${LOCAL_DORADO_BIN}/dorado")

  log_info "Adding dorado executable ${DORADO_EXECUTABLE_PATH} to runtime config ${RUNTIME_CONFIG}"
  cat >> "${RUNTIME_CONFIG}" << EOL
#!/bin/bash
# dorado executable
export DORADO_EXECUTABLE="${DORADO_EXECUTABLE_PATH}"

EOL

  log_info "Dorado was successfully installed. Dorado path was saved to ${RUNTIME_CONFIG}" >&2
}

download_reference_genome() {

  log_info "Checking for reference genome"

  REF_FASTA="${REFERENCE_GENOME_DIR}${REFERENCE_GENOME_NAME}"


  # Check to see whether the file already exists.
  if [ -f "${REF_FASTA}" ]; then
    log_info "Reference file ${REF_FASTA} already exists, so we will skip the download"
    return 0
  fi

  log_info "--- Reference genome not found at ${REF_FASTA}. Downloading from ${REFERENCE_GENOME_URL} to ${REFERENCE_GENOME_DIR} ---"

  aws s3 cp "${REFERENCE_GENOME_URL}" "${REF_FASTA}" --no-sign-request

  log_info "Genome has been downloaded and indexed."

  # The output of this should be in the format >chr1 >chr2 etc.
  # grep ">" "${REF_FASTA}" | head -n 5
}

index_reference_genome() {
  REF_FASTA="${REFERENCE_GENOME_DIR}${REFERENCE_GENOME_NAME}"
  REF_MMI="${REFERENCE_GENOME_DIR}${REFERENCE_GENOME_INDEX}"

  log_info "Checking for reference index at ${REF_MMI}"
  if [ ! -f "${REF_MMI}" ]; then
    log_info "Index not found, creating minimap2 index"
    minimap2 -d "${REF_MMI}" "${REF_FASTA}"
    log_info "Genome index created at ${REF_MMI}"
  else
    log_info "Index already exists, so we'll skip indexing."
  fi
}

download_fast5_data() {
  mkdir -p "${FAST5_DESTINATION_DIR}"

  log_info "--- Downloading ${NUM_FAST5_FILES} fast5 files into '${FAST5_DESTINATION_DIR}' ---"
  log_info "--- Downloading from '${FAST5_DOWNLOAD_URL}'"

  log_info "Starting to download fast5 data, starting from finding the file names."
  start_time=$(date +%s%N)


  ALL_S3_FILENAMES=$(aws s3 ls "${FAST5_DOWNLOAD_URL}" --no-sign-request | grep '\.fast5' | awk '{print $4}')

  if [[ "${NUM_FAST5_FILES}" == "all" ]]; then
    log_info "Preparing to download all available files."
    filenames_to_download="${ALL_S3_FILENAMES}"
  else
    log_info "INFO: Preparing to download the first ${NUM_FAST5_FILES} files."
    filenames_to_download=$(echo "${ALL_S3_FILENAMES}" | head -n "${NUM_FAST5_FILES}")
  fi

  log_info "Starting download..." >&2
  echo "${filenames_to_download}" | while read -r filename; do
    # skip any empty lines
    if [[ -z "$filename" ]]; then
      continue
    fi

    local destination="${FAST5_DESTINATION_DIR}"
    if [ ! -f "$destination" ]; then
      aws s3 cp "${FAST5_DOWNLOAD_URL}${filename}" "${destination}" --no-sign-request --quiet
    fi
  done

  end_time=$(date +%s%N)
  duration=$(awk "BEGIN {printf \"%.2f\", ($end_time - $start_time) / 1000000000}")
  log_info "Fast5 download process finished in ${duration} seconds"

  #aws s3 ls "${FAST5_DOWNLOAD_URL}" --no-sign-request \
  #| head -n "${NUM_FAST5_FILES}" \
  #| awk '{print $4}' \
  #| while read -r filename; do
  #    aws s3 cp "${FAST5_DOWNLOAD_URL}${filename}" "${FAST5_DESTINATION_DIR}" --no-sign-request --quiet || true
  #done

  log_info "--- Fast5 input downloaded ---"

}

convert_fast5_to_pod5() {
  log_info "--- Converting fast5 to pod5 ---"

  mkdir -p "${POD5_DIR}"

  local pod5_cmd=(
    "pod5"
    "convert"
    "fast5"
    "${FAST5_DESTINATION_DIR}"
    "--output"
    "${POD5_DIR}/${POD5_FILE}"
    "--force-overwrite"
  )

  log_info "Converting fast5 to pod5, command: ${pod5_cmd[*]}"

  "${pod5_cmd[@]}" 2>/dev/null # Suppress progress bar.
}

download_methylation_atlas_and_illumina_manifest(){
  mkdir -p "data/atlas/"
  if ! [ -f "data/atlas/illumina_manifest.csv" ]; then
    log_info "The illumina manifest doesn't already exist, so we will download it."
    wget https://webdata.illumina.com/downloads/productfiles/humanmethylation450/humanmethylation450_15017482_v1-2.csv -q -O "data/atlas/illumina_manifest.csv"
  else
    log_info "The illumina manifest is already there so won't be re-downloaded."
  fi
  if ! [ -f "data/atlas/full_atlas.csv" ]; then
    log_info "The methylation atlas doesn't already exist, so we will download it."
    wget https://github.com/nloyfer/meth_atlas/raw/refs/heads/master/full_atlas.csv.gz -q -O "data/atlas/full_atlas.csv.gz"
    gunzip -v "data/atlas/full_atlas.csv.gz"
    #rm "data/atlas/full_atlas.csv.gz"
  else
    log_info "The methylation atlas is already there so won't be re-downloaded."
  fi
  if ! [ -f "data/atlas/UXM_atlas.tsv" ]; then
    log_info "The UXM atlas doesn't already exist, so we'll download it."
    wget https://raw.githubusercontent.com/nloyfer/UXM_deconv/refs/heads/main/supplemental/Atlas.U25.l4.hg19.tsv -q -O "data/atlas/UXM_atlas.tsv"
  else
    log_info "The UXM atlas tsv file is already there so won't be re-downloaded."
  fi
  if [ -f "data/atlas/UXM_atlas.tsv" ] && [ ! -f "data/atlas/UXM_atlas.csv" ]; then
    log_info "The UXM atlas doesn't exist as a csv file, so we'll use the .tsv file to make it."
    tr '\t' ',' < "data/atlas/UXM_atlas.tsv" > "data/atlas/UXM_atlas.csv"
    log_info "csv file created."
  else
    log_info "The UXM atlas csv file is already there so won't be re-downloaded."
  fi
}

setup_submodules() {
  log_info "Setting up submodules"

  if [ ! -f ".gitmodules" ]; then
    log_warning "No .gitmodules file found. Skipping submodule setup."
    return 0
  fi

  log_info "Synchronising submodule URLs..."
  git submodule sync --recursive
  log_info "Forcibly updating submodules to the correct commit..."
  git submodule update --init --recursive --force
  log_info "All submodules have been synced and are ready to go."

  # Add a check to see whether it's already been compiled...figure this out.
  #install_wgbstools
  patch_wgbstools_wrapper
  patch_uxm_wrapper
}

install_wgbstools() {
  log_info "Compiling wgbstools"
  log_info "Running command cd externals/wgbstools && python setup.py"

  (cd externals/wgbs_tools && python setup.py)

  log_info "wgbstools compiled successfully."

}

patch_wgbstools_wrapper() {
  WGBS_TOOLS_DIR="${PWD}/externals/wgbs_tools"
  WGBS_PY_PATH="${WGBS_TOOLS_DIR}/src/python/wgbs_tools.py"

  FULL_WGBS_PY_PATH="$(realpath "${WGBS_PY_PATH}")"

  cat >> "${RUNTIME_CONFIG}" << EOL
# Absolute path to WGBS
export WGBSTOOLS_EXE=${FULL_WGBS_PY_PATH}
EOL

  log_info "${FULL_WGBS_PY_PATH} added to runtime config"
}

patch_uxm_wrapper() {
  log_info "Adding uxm python exe to runtim_config"

  UXM_DECONV_DIR="${PWD}/externals/UXM_deconv"
  UXM_PY_PATH="${UXM_DECONV_DIR}/src/uxm.py"

  FULL_UXM_PY_PATH="$(realpath "${UXM_PY_PATH}")"

  cat >> "${RUNTIME_CONFIG}" << EOL
# Absolute path to UXM
export UXM_EXE=${FULL_UXM_PY_PATH}
EOL
  log_info "${FULL_UXM_PY_PATH} added to runtime config"

}

make_directories
#download_reference_genome
#index_reference_genome
setup_submodules
install_dorado
download_methylation_atlas_and_illumina_manifest
if [[ "$SHOULD_DOWNLOAD_FAST5_FILES" == "true" ]]; then
  download_fast5_data
fi
if [[ "$SHOULD_CONVERT_FAST5_TO_POD5" == "true" ]]; then
  convert_fast5_to_pod5
fi

trap 'handle_error $LINENO' ERR