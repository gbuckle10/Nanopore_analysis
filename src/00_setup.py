import platform
from utils.runner import load_config, get_project_root, run_external_command, run_wgbstools
import os
import subprocess
import sys
import csv
import requests
import tarfile
import gzip
import shutil
import zipfile
import yaml

project_root = get_project_root()
CONFIG_PATH = os.path.join(project_root, "config.yaml")
RUNTIME_CONFIG_PATH = os.path.join(project_root, "src", "runtime_config.yaml")


def download_file(url, destination):
    print(f"Downloading from {url} to {destination}")

    try:
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            with open(destination, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
    except requests.exceptions.RequestException as e:
        print(f"Error downloading file: {e}", file=sys.stderr)
        sys.exit(1)


def make_directories(config):
    """
    Creates all directories specified in the config file.
    """
    print("--- Creating core directory structure ---")

    for directory in config['paths']['core_directories']:
        abs_path = os.path.join(project_root, directory)
        os.makedirs(abs_path, exist_ok=True)

    with open(RUNTIME_CONFIG_PATH, 'w') as f:
        f.write('#!/bin/bash\n')
        f.write('# Auto-generated by 00_setup.py. Do not edit manually')
    print(f"Initialised runtime config at {RUNTIME_CONFIG_PATH}")


def install_dorado(config):
    """
    Downloads and extracts the correct version of Dorado.
    """
    print(" --- Setting up Dorado ---")
    version = config['parameters']['setup']['dorado_version']
    system = platform.system()

    if system == 'Linux':
        os_type = 'linux-x64'
        archive_filename = f"dorado-{version}-{os_type}.tar.gz"
        download_url = f"https://cdn.oxfordnanoportal.com/software/analysis/dorado-{version}-{os_type}.tar.gz"
    elif system == 'Windows':
        os_type = 'win64'
        archive_filename = f"dorado-{version}-{os_type}.tar.gz"
        download_url = f"https://cdn.oxfordnanoportal.com/software/analysis/dorado-{version}-{os_type}.zip"
    else:
        print(f"You're using an operating system I don't know - {system}")
        sys.exit(1)

    dorado_dir = f"{project_root}/tools/dorado-{version}-{os_type}"

    print(f"Checking for dorado at {dorado_dir}")

    if os.path.isdir(dorado_dir):
        print(f"Dorado already found at {dorado_dir}. Writing to config.yaml and skipping download.")
        dorado_exe_path = os.path.abspath(os.path.join(dorado_dir, "bin", "dorado"))
        print(f"Adding dorado executable path {dorado_exe_path} to config.yaml")
        config['paths']['tools']['dorado'] = dorado_exe_path
        return dorado_dir
    else:
        print(f"Downloading dorado version {version} for {os_type} from {download_url}")
        archive_path = os.path.join(project_root, "tools", archive_filename)
        download_file(download_url, archive_path)

        print(f"Extracting {archive_path}...")
        if archive_path.endswith(".tar.gz"):
            with tarfile.open(archive_path, "r:gz") as tar:
                tar.extractall(path="tools")
        elif archive_path.endswith(".zip"):
            with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                zip_ref.extractall(path="tools")
        os.remove(archive_path)
        print("Extraction complete")

    dorado_exe_path = os.path.abspath(os.path.join(dorado_dir, "bin", "dorado"))
    print(f"Adding dorado executable path {dorado_exe_path} to config.yaml")
    config['paths']['tools']['dorado'] = dorado_exe_path

    return dorado_exe_path


def setup_submodules(config):
    print(" --- Setting up git submodules. ---")
    if not os.path.exists(f"{project_root}/.gitmodules"):
        print("No gitmodules file found. Skipping submodule setup.")
        return

    sync_command = ["git", "submodule", "sync", "--recursive"]
    update_command = ["git", "submodule", "update", "--init", "--recursive", "--force"]

    run_external_command(sync_command)
    run_external_command(update_command)

    print("Compiling wgbstools")


    comp_command = ["python", "setup.py"]
    #run_external_command(comp_command, cwd=wgbstools_dir)

    # The code block below will write the config file with the wgbstools dir in the config.
    # Wait until config/template config is properly set up to use this block.
    '''
    wgbstools_dir = f"{project_root}/externals/wgbs_tools"
    config['paths']['tools']['wgbstools'] = wgbstools_dir
    config_path = project_root / "config.yaml"
    with open(config_path, 'w') as f:
        yaml.dump(config, f, sort_keys=False, indent=2)
    '''

    uxm_dir = f"{project_root}/externals/UXM_deconv"
    uxm_exe_path = os.path.abspath(os.path.join(uxm_dir, "src/uxm.py"))
    with open(RUNTIME_CONFIG_PATH, 'a') as f:
        f.write(f'export UXM_EXE="{uxm_exe_path}"\n')
    print(f"uxm path added to {RUNTIME_CONFIG_PATH}")


def download_atlas_manifest_files(config):
    print("--- Downloading and preparing atlas files and manifests ---")
    atlas_dir = os.path.join(project_root, "data/atlas")
    os.makedirs("data/atlas", exist_ok=True)

    files_to_download = {
        "illumina_manifest.csv": "https://webdata.illumina.com/downloads/productfiles/humanmethylation450/humanmethylation450_15017482_v1-2.csv",
        "full_atlas.csv": "https://github.com/nloyfer/meth_atlas/raw/refs/heads/master/full_atlas.csv.gz",
        "UXM_atlas.tsv": "https://raw.githubusercontent.com/nloyfer/UXM_deconv/refs/heads/main/supplemental/Atlas.U25.l4.hg19.tsv"
    }

    for filename, url in files_to_download.items():
        dest_path = os.path.join(atlas_dir, filename)
        if not os.path.exists(dest_path):
            download_file(url, dest_path)
        else:
            print(f"{filename} already exists. Skipping download.")

    gz_path = os.path.join(atlas_dir, "full_atlas.csv.gz")
    csv_path = os.path.join(atlas_dir, "full_atlas.csv")
    if os.path.exists(gz_path) and not os.path.exists(csv_path):
        print("Decompressing full_atlas.csv.gz...")
        with gzip.open(gz_path, 'rb') as f_in:
            with open(csv_path, 'wb') as f_out:
                shutil.copyfileobj(f_in, f_out)

    # Convert UXM_atlas.tsv to .csv
    tsv_path = os.path.join(atlas_dir, "UXM_atlas.tsv")
    uxm_csv_path = os.path.join(atlas_dir, "UXM_atlas.csv")
    if os.path.exists(tsv_path) and not os.path.exists(uxm_csv_path):
        print("Converting UXM_atlas.tsv to UXM_atlas.csv")
        with open(tsv_path, 'r') as tsv_file, open(uxm_csv_path, 'w', newline='') as csv_file:
            reader = csv.reader(tsv_file, delimiter='\t')
            writer = csv.writer(uxm_csv_path, delimiter=',')
            for row in reader:
                writer.writerow(row)


def download_and_index_reference_genome_manual(config):
    """
    Downloads the reference genomes with AWS CLI and indexes it with minimap 2.
    """
    genome = config['paths']['reference_genome']
    print(f"--- Setting up reference genome {genome} ---")

    ref_dir = os.path.join(project_root, 'reference_genomes', genome)
    os.makedirs(ref_dir, exist_ok=True)
    ref_fasta = os.path.join(ref_dir, config['paths']['reference_genome_fasta_name'])
    ref_mmi = os.path.join(ref_dir, config['paths']['indexed_ref_gen_fasta_name'])

    if not os.path.exists(ref_fasta):
        # Maybe we'll hardcode the reference genome urls in this function...
        ref_url = config['paths']['reference_genome_url']
        print(f"Reference file {ref_fasta} doesn't exist. Downloading from {ref_url}")
        run_external_command([
            "aws", "c3", "cp", ref_url, ref_fasta, "--no-sign-request"
        ])
    else:
        print("Reference genome already exists.")

    if not os.path.exists(ref_mmi):
        print("Indexing reference genome with minimap2...")
        run_external_command([
            "minimap2", "-d", ref_mmi, ref_fasta
        ])
    else:
        print(f"Reference genome index already exists.")


def download_and_index_reference_genome(config):
    """
    Use wgbstools init_genome to initialise the specified genome.
    """
    genome = config['paths']['reference_genome']
    print(f"Initialising reference genome {genome}")
    wgbstools_cmd = [
        "wgbstools", "init_genome",
        genome
    ]

    run_wgbstools(wgbstools_cmd)


def download_fast5_data(config):
    print("--- Downloading sample fast5 data ---")
    fast5_dir = os.path.join(project_root, config['paths']['fast5_input_dir'])
    number_to_download = config['parameters']['setup']['num_fast5_files']
    print(f"Downloading {number_to_download} fast5 files into {fast5_dir}")
    url = config['paths']['fast5_download_url']


    os.makedirs(fast5_dir, exist_ok=True)

    cmd_file_list = [
        "aws", "s3", "ls", url, "--no-sign-request"
    ]

    try:
        result = subprocess.run(
            cmd_file_list, check=True, capture_output=True, text=True
        )

        all_files = []
        for line in result.stdout.strip().split('\n'):
            if ".fast5" in line:
                filename = line.split()[-1]
                all_files.append(filename)

    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        print(f"Failed to list S3 bucket contents, make sure AWS CLI is installed and working", file=sys.stderr)
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)



    if str(number_to_download).lower() == 'all':
        files_to_download = all_files
        print(f"Preparing to download all {len(files_to_download)} files.")
    else:
        try:
            files_to_download = all_files[:int(number_to_download)]
            print(f"Preparing to download the first {len(files_to_download)} files")
        except ValueError:
            print(f"'num_fast5_files' in config is not a number or 'all'. Value is {number_to_download}",
                  file=sys.stderr)
            sys.exit(1)

    print("Starting download...")
    for filename in files_to_download:
        if not filename:
            # A blank line
            continue
        source_path = f"{url}{filename}"
        local_dest = os.path.join(fast5_dir, filename)

        if os.path.exists(local_dest):
            print(f"Skipping {filename}, already exists.")
            continue

        dl_cmd = [
            "aws", "s3", "cp", source_path, fast5_dir, "--no-sign-request", "--quiet"
        ]

        run_external_command(dl_cmd)

    print("--- Fast5 download complete! --- ")


def convert_fast5_to_pod5(config):
    print("--- Converting fast5 to pod5 ---")
    pod5_dir = os.path.join(project_root, config['paths']['pod5_dir'])
    fast5_dir = os.path.join(project_root, config['paths']['fast5_input_dir'])

    os.makedirs(config['paths']['pod5_dir'], exist_ok=True)

    pod5_cmd = [
        'pod5', 'convert', 'fast5',
        fast5_dir,
        '--output', pod5_dir,
        '--force-overwrite'
    ]

    print(f"Converting fast5 to pod5, command: {' '.join(pod5_cmd)}")
    run_external_command(pod5_cmd)


def main():
    config = load_config(CONFIG_PATH)
    runtime_tool_paths = {}
    make_directories(config)


    setup_submodules(config)
    download_atlas_manifest_files(config)
    # download_and_index_reference_genome(config)

    if config['pipeline_control']['run_setup_tasks']['download_fast5_data']:
        download_fast5_data(config)
    if config['pipeline_control']['run_setup_tasks']['convert_fast5_to_pod5']:
        convert_fast5_to_pod5(config)


if __name__ == "__main__":
    main()
